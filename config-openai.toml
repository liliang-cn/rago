# Pure OpenAI Configuration
# Use OpenAI for both LLM and embeddings

[server]
port = 7127
host = "0.0.0.0"
enable_ui = true

[providers]
default_llm = "openai"
default_embedder = "openai"

[providers.openai]
type = "openai"
api_key = "sk-your-openai-api-key-here"
base_url = "https://api.openai.com/v1"
llm_model = "gpt-4"
embedding_model = "text-embedding-3-small"
timeout = "60s"

[sqvect]
db_path = "./data/rag.db"
vector_dim = 1536  # OpenAI text-embedding-3-small dimension
max_conns = 10
batch_size = 100
top_k = 5
threshold = 0.0

[keyword]
index_path = "./data/keyword.bleve"

[chunker]
chunk_size = 500
overlap = 50
method = "sentence"

[ingest]
[ingest.metadata_extraction]
enable = true
llm_model = "gpt-4"

[tools]
enabled = true
max_concurrent_calls = 5
call_timeout = "30s"
security_level = "normal"
enabled_tools = [
    "datetime",
    "rag_search", 
    "document_info",
    "web_request",
    "google_search"
]