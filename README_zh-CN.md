# RAGO - ç®€åŒ–æœ¬åœ° RAG ç³»ç»Ÿ

[English Documentation](README.md)

RAGO (Retrieval-Augmented Generation Offline) v2 æ˜¯ä¸€ä¸ªæµçº¿å‹ã€ç”Ÿäº§å°±ç»ªçš„ RAG ç³»ç»Ÿï¼Œé‡‡ç”¨ Go è¯­è¨€ç¼–å†™ã€‚å®ƒæä¾›ç®€æ´çš„ API ç”¨äºæ–‡æ¡£æ‘„å–ã€è¯­ä¹‰æœç´¢å’Œä¸Šä¸‹æ–‡å¢å¼ºé—®ç­”ï¼Œä¸“æ³¨äºç®€å•æ€§å’Œå¯é æ€§ã€‚

## ğŸŒŸ æ ¸å¿ƒåŠŸèƒ½ï¼ˆv2 ç®€åŒ–ç‰ˆï¼‰

### ğŸ“š **RAG ç³»ç»Ÿï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼‰**
- **æ–‡æ¡£æ‘„å–** - å¯¼å…¥æ–‡æœ¬ã€Markdownã€PDF æ–‡ä»¶å¹¶è‡ªåŠ¨åˆ†å—
- **å‘é‡æ•°æ®åº“** - åŸºäº SQLite çš„å‘é‡å­˜å‚¨ï¼Œä½¿ç”¨ sqvect å®ç°é«˜æ€§èƒ½æœç´¢
- **è¯­ä¹‰æœç´¢** - ä½¿ç”¨åµŒå…¥ç›¸ä¼¼æ€§æŸ¥æ‰¾ç›¸å…³æ–‡æ¡£
- **æ™ºèƒ½åˆ†å—** - å¯é…ç½®çš„æ–‡æœ¬åˆ†å‰²ï¼ˆå¥å­ã€æ®µè½ã€è¯å…ƒæ–¹æ³•ï¼‰
- **é—®ç­”ç”Ÿæˆ** - ä½¿ç”¨æ£€ç´¢æ–‡æ¡£è¿›è¡Œä¸Šä¸‹æ–‡å¢å¼ºå›ç­”
- **å…ƒæ•°æ®æå–** - è‡ªåŠ¨ç”Ÿæˆæ–‡æ¡£çš„å…³é”®è¯å’Œæ‘˜è¦

### ğŸ”§ **OpenAI å…¼å®¹ LLM æ”¯æŒ**
- **ç»Ÿä¸€æä¾›å•†æ¥å£** - æ‰€æœ‰ LLM æœåŠ¡ä½¿ç”¨å•ä¸€ OpenAI å…¼å®¹ API
- **æœ¬åœ°ä¼˜å…ˆ** - æ”¯æŒ Ollamaã€LM Studio å’Œä»»ä½• OpenAI å…¼å®¹æœåŠ¡å™¨
- **æµå¼æ”¯æŒ** - å®æ—¶ä»¤ç‰Œæµå¼ä¼ è¾“ä»¥è·å¾—æ›´å¥½çš„ç”¨æˆ·ä½“éªŒ
- **ç»“æ„åŒ–ç”Ÿæˆ** - ç”Ÿæˆç¬¦åˆç‰¹å®šæ¨¡å¼çš„ JSON è¾“å‡º
- **å¥åº·ç›‘æ§** - å†…ç½®æä¾›å•†å¥åº·æ£€æŸ¥

### ğŸ› ï¸ **MCP å·¥å…·é›†æˆ**
- **æ¨¡å‹ä¸Šä¸‹æ–‡åè®®** - æ ‡å‡†å·¥å…·é›†æˆæ¡†æ¶
- **å†…ç½®å·¥å…·** - filesystemã€fetchã€memoryã€timeã€sequential-thinking
- **å¤–éƒ¨æœåŠ¡å™¨** - è¿æ¥ä»»ä½• MCP å…¼å®¹çš„å·¥å…·æœåŠ¡å™¨
- **æŸ¥è¯¢å¢å¼º** - åœ¨ RAG æŸ¥è¯¢æœŸé—´ä½¿ç”¨å·¥å…·è·å¾—æ›´ä¸°å¯Œçš„ç­”æ¡ˆ

### ğŸ’» **å¼€å‘è€…ä½“éªŒ**
- **ç®€æ´åº“ API** - æ‰€æœ‰æ“ä½œçš„ç®€å•ã€ç›´è§‚æ¥å£
- **é›¶é…ç½®æ¨¡å¼** - ä½¿ç”¨æ™ºèƒ½é»˜è®¤å€¼å¼€ç®±å³ç”¨
- **HTTP API** - æ‰€æœ‰æ“ä½œçš„ RESTful ç«¯ç‚¹
- **é«˜æ€§èƒ½** - ä¼˜åŒ–çš„ Go å®ç°ï¼Œä¾èµ–æœ€å°‘

## ğŸš€ å¿«é€Ÿå¼€å§‹ï¼ˆé›¶é…ç½®ï¼ï¼‰

**âœ¨ RAGO v2 æ— éœ€ä»»ä½•é…ç½®å³å¯è¿è¡Œï¼**

### å®‰è£…

```bash
# é€‰é¡¹ 1ï¼šç›´æ¥å®‰è£…
go install github.com/liliang-cn/rago/v2@latest

# é€‰é¡¹ 2ï¼šå…‹éš†å¹¶æ„å»º
git clone https://github.com/liliang-cn/rago.git
cd rago
go build -o rago ./cmd/rago-cli

# é€‰é¡¹ 3ï¼šä½¿ç”¨ Makefile
make build
```

### ğŸ¯ é›¶é…ç½®ä½¿ç”¨

RAGO v2 å¼€ç®±å³ç”¨åœ°æ”¯æŒ OpenAI å…¼å®¹çš„æä¾›å•†ï¼š

```bash
# æ£€æŸ¥ç³»ç»ŸçŠ¶æ€ï¼ˆæ— éœ€é…ç½®ï¼ï¼‰
./rago status

# å°†æ–‡æ¡£å¯¼å…¥ RAG çŸ¥è¯†åº“
./rago rag ingest document.pdf
./rago rag ingest "path/to/text/file.txt"
./rago rag ingest --text "ç›´æ¥æ–‡æœ¬å†…å®¹" --source "æˆ‘çš„æ–‡æ¡£"

# æŸ¥è¯¢æ‚¨çš„çŸ¥è¯†åº“
./rago rag query "è¿™ä¸ªæ–‡æ¡£æ˜¯å…³äºä»€ä¹ˆçš„ï¼Ÿ"

# åˆ—å‡ºæ‰€æœ‰å·²ç´¢å¼•çš„æ–‡æ¡£
./rago rag list

# äº¤äº’æ¨¡å¼ï¼ˆå¦‚æœå¯ç”¨ï¼‰
./rago rag query -i

# å¯ç”¨ MCP å·¥å…·ï¼ˆå¦‚æœå¯ç”¨ï¼‰
./rago rag query "åˆ†æè¿™äº›æ•°æ®å¹¶ä¿å­˜ç»“æœ" --mcp
```

### ç¯å¢ƒå˜é‡ï¼ˆå¯é€‰ï¼‰

```bash
# ç”¨äº OpenAI å…¼å®¹æœåŠ¡
# API å¯†é’¥æ˜¯å¯é€‰çš„ - ç”±æä¾›å•†å¤„ç†è®¤è¯
export RAGO_OPENAI_API_KEY="your-api-key"  # å¯é€‰
export RAGO_OPENAI_BASE_URL="http://localhost:11434/v1"  # Ollama
export RAGO_OPENAI_LLM_MODEL="qwen3"
export RAGO_OPENAI_EMBEDDING_MODEL="nomic-embed-text"
```


## ğŸ“– åº“ä½¿ç”¨

### RAG å®¢æˆ·ç«¯ APIï¼ˆæ¨èï¼‰

ç®€åŒ–çš„ RAG å®¢æˆ·ç«¯ä¸ºæ‰€æœ‰æ“ä½œæä¾›æ¸…æ™°çš„æ¥å£ï¼š

```go
import (
    "context"
    "fmt"
    "github.com/liliang-cn/rago/v2/pkg/rag"
    "github.com/liliang-cn/rago/v2/pkg/config"
    "github.com/liliang-cn/rago/v2/pkg/providers"
)

// ä½¿ç”¨é»˜è®¤é…ç½®åˆå§‹åŒ–
cfg, _ := config.Load("")  // ç©ºå­—ç¬¦ä¸²è¡¨ç¤ºé»˜è®¤å€¼
cfg.Providers.DefaultLLM = "openai"
cfg.Providers.OpenAI.BaseURL = "http://localhost:11434/v1"  // Ollama
cfg.Providers.OpenAI.LLMModel = "qwen3"
cfg.Providers.OpenAI.EmbeddingModel = "nomic-embed-text"

// åˆ›å»ºæä¾›å•†
embedder, _ := providers.CreateEmbedderProvider(context.Background(), cfg.Providers.OpenAI)
llm, _ := providers.CreateLLMProvider(context.Background(), cfg.Providers.OpenAI)

// åˆ›å»º RAG å®¢æˆ·ç«¯
client, _ := rag.NewClient(cfg, embedder, llm, nil)
defer client.Close()

// æ‘„å–æ–‡æ¡£
ctx := context.Background()
resp, err := client.IngestFile(ctx, "document.pdf", rag.DefaultIngestOptions())
fmt.Printf("å·²æ‘„å– %d ä¸ªå—\n", resp.ChunkCount)

// æŸ¥è¯¢çŸ¥è¯†åº“
queryResp, err := client.Query(ctx, "è¿™ä¸ªæ–‡æ¡£æ˜¯å…³äºä»€ä¹ˆçš„ï¼Ÿ", rag.DefaultQueryOptions())
fmt.Printf("å›ç­”: %s\n", queryResp.Answer)
fmt.Printf("æ¥æº: %d\n", len(queryResp.Sources))

// ç›´æ¥æ‘„å–æ–‡æœ¬
textResp, err := client.IngestText(ctx, "æ‚¨çš„æ–‡æœ¬å†…å®¹", "source.txt", rag.DefaultIngestOptions())
fmt.Printf("æ–‡æœ¬å·²æ‘„å–ï¼ŒID: %s\n", textResp.DocumentID)
```

### LLM æœåŠ¡ API

ç”¨äºç›´æ¥ LLM æ“ä½œï¼š

```go
import (
    "context"
    "github.com/liliang-cn/rago/v2/pkg/llm"
    "github.com/liliang-cn/rago/v2/pkg/domain"
)

// åˆ›å»º LLM æœåŠ¡
llmService := llm.NewService(llmProvider)

// ç®€å•ç”Ÿæˆ
response, err := llmService.Generate(ctx, "å†™ä¸€é¦–ä¿³å¥", &domain.GenerationOptions{
    Temperature: 0.7,
    MaxTokens:   100,
})

// æµå¼ç”Ÿæˆ
err = llmService.Stream(ctx, "ç»™æˆ‘è®²ä¸ªæ•…äº‹", &domain.GenerationOptions{
    Temperature: 0.8,
    MaxTokens:   500,
}, func(chunk string) {
    fmt.Print(chunk)
})

// å·¥å…·è°ƒç”¨
messages := []domain.Message{
    {Role: "user", Content: "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"},
}
tools := []domain.ToolDefinition{
    // åœ¨è¿™é‡Œå®šä¹‰æ‚¨çš„å·¥å…·
}
result, err := llmService.GenerateWithTools(ctx, messages, tools, &domain.GenerationOptions{})
```

### åŸºäºé…ç½®çš„ä½¿ç”¨

åˆ›å»º `rago.toml` é…ç½®æ–‡ä»¶ï¼š

```toml
[providers]
default_llm = "openai"
default_embedder = "openai"

[providers.openai]
type = "openai"
base_url = "http://localhost:11434/v1"  # Ollama ç«¯ç‚¹
api_key = "ollama"  # å³ä½¿æœ¬åœ°ä¹Ÿéœ€è¦
llm_model = "qwen3"
embedding_model = "nomic-embed-text"
timeout = "30s"

[sqvect]
db_path = "~/.rago/data/rag.db"
top_k = 5
threshold = 0.0

[chunker]
chunk_size = 500
overlap = 50
method = "sentence"

[mcp]
enabled = true
```

ç„¶ååœ¨ä»£ç ä¸­ä½¿ç”¨ï¼š

```go
cfg, _ := config.Load("rago.toml")
// ... å…¶ä½™åˆå§‹åŒ–ä»£ç 
```

## ğŸ› ï¸ MCP å·¥å…·

### å†…ç½®å·¥å…·

- **filesystem** - æ–‡ä»¶æ“ä½œï¼ˆè¯»ã€å†™ã€åˆ—è¡¨ã€æ‰§è¡Œï¼‰
- **fetch** - HTTP/HTTPS è¯·æ±‚
- **memory** - ä¸´æ—¶é”®å€¼å­˜å‚¨
- **time** - æ—¥æœŸ/æ—¶é—´æ“ä½œ
- **sequential-thinking** - LLM åˆ†æå’Œæ¨ç†

### å·¥å…·é…ç½®

åœ¨ `mcpServers.json` ä¸­é…ç½® MCP æœåŠ¡å™¨ï¼š

```json
{
  "filesystem": {
    "command": "npx",
    "args": ["@modelcontextprotocol/server-filesystem", "/path/to/allowed/directory"],
    "description": "æ–‡ä»¶ç³»ç»Ÿæ“ä½œ"
  },
  "fetch": {
    "command": "npx",
    "args": ["@modelcontextprotocol/server-fetch"],
    "description": "HTTP/HTTPS æ“ä½œ"
  }
}
```

## ğŸ“Š HTTP API

å¯åŠ¨ API æœåŠ¡å™¨ï¼š

```bash
./rago serve --port 7127
```

### æ ¸å¿ƒç«¯ç‚¹

#### RAG æ“ä½œ
- `POST /api/rag/ingest` - å°†æ–‡æ¡£æ‘„å–åˆ°å‘é‡æ•°æ®åº“
- `POST /api/rag/query` - æ‰§è¡Œå¸¦ä¸Šä¸‹æ–‡æ£€ç´¢çš„ RAG æŸ¥è¯¢
- `GET /api/rag/list` - åˆ—å‡ºå·²ç´¢å¼•çš„æ–‡æ¡£
- `DELETE /api/rag/reset` - æ¸…ç©ºå‘é‡æ•°æ®åº“
- `GET /api/rag/collections` - åˆ—å‡ºæ‰€æœ‰é›†åˆ

#### MCP å·¥å…·
- `GET /api/mcp/tools` - åˆ—å‡ºå¯ç”¨çš„ MCP å·¥å…·
- `POST /api/mcp/tools/call` - æ‰§è¡Œ MCP å·¥å…·
- `GET /api/mcp/status` - æ£€æŸ¥ MCP æœåŠ¡å™¨çŠ¶æ€

## âš™ï¸ é…ç½®

### ç¯å¢ƒå˜é‡ï¼ˆç®€å•ï¼‰

```bash
# åŸºæœ¬ OpenAI å…¼å®¹é…ç½®
export RAGO_OPENAI_API_KEY="your-api-key"
export RAGO_OPENAI_BASE_URL="http://localhost:11434/v1"
export RAGO_OPENAI_LLM_MODEL="qwen3"
export RAGO_OPENAI_EMBEDDING_MODEL="nomic-embed-text"

# æœåŠ¡å™¨è®¾ç½®
export RAGO_SERVER_PORT="7127"
export RAGO_SERVER_HOST="0.0.0.0"
```

### é…ç½®æ–‡ä»¶ï¼ˆé«˜çº§ï¼‰

åˆ›å»º `rago.toml` è¿›è¡Œå®Œå…¨æ§åˆ¶ï¼š

```toml
[server]
port = 7127
host = "0.0.0.0"
enable_ui = false

[providers]
default_llm = "openai"
default_embedder = "openai"

[providers.openai]
type = "openai"
base_url = "http://localhost:11434/v1"  # Ollama ç«¯ç‚¹
api_key = "ollama"
llm_model = "qwen3"
embedding_model = "nomic-embed-text"
timeout = "30s"

[sqvect]
db_path = "~/.rago/data/rag.db"
top_k = 5
threshold = 0.0

[chunker]
chunk_size = 500
overlap = 50
method = "sentence"

[mcp]
enabled = true
servers_config_path = "mcpServers.json"
```

## ğŸ“š æ–‡æ¡£

### API å‚è€ƒ
- **[RAG å®¢æˆ·ç«¯ API](./pkg/rag/)** - æ ¸å¿ƒ RAG å®¢æˆ·ç«¯æ–‡æ¡£
- **[LLM æœåŠ¡ API](./pkg/llm/)** - LLM æœåŠ¡æ–‡æ¡£
- **[é…ç½®æŒ‡å—](./pkg/config/)** - å®Œæ•´é…ç½®é€‰é¡¹
- **[English Docs](./README.md)** - è‹±æ–‡æ–‡æ¡£

### ç¤ºä¾‹ï¼ˆå³å°†æ¨å‡ºï¼‰
æˆ‘ä»¬æ­£åœ¨æ›´æ–°ç®€åŒ– v2 API çš„ç¤ºä¾‹ã€‚æ•¬è¯·æœŸå¾…ï¼š
- åŸºæœ¬ RAG å®¢æˆ·ç«¯ä½¿ç”¨
- LLM æœåŠ¡ç¤ºä¾‹
- MCP å·¥å…·é›†æˆ
- é…ç½®æ¨¡å¼

## ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®ï¼è¯·æŸ¥çœ‹ [CONTRIBUTING.md](CONTRIBUTING.md) äº†è§£æŒ‡å—ã€‚

## ğŸ“„ è®¸å¯è¯

MIT è®¸å¯è¯ - è¯¦æƒ…è¯·è§ [LICENSE](LICENSE)

## ğŸ”— é“¾æ¥

- [GitHub ä»“åº“](https://github.com/liliang-cn/rago)
- [é—®é¢˜è·Ÿè¸ª](https://github.com/liliang-cn/rago/issues)
- [è®¨è®ºåŒº](https://github.com/liliang-cn/rago/discussions)
