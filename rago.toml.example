# RAGO (Retrieval-Augmented Generation Offline) Configuration Example
# Place this file in your project root or ~/.rago/rago.toml

# RAGO Home directory - unified path for all data, skills, and intents
# Defaults to the directory containing this file if not set
# home = "~/.rago"

[llm_pool]
enabled = true
strategy = "round_robin" # round_robin, random, least_load, capability, failover

[[llm_pool.providers]]
name = "qwen3"
base_url = "http://localhost:11434/v1"  # Default Ollama URL
key = ""                                # API Key if required
model_name = "qwen3:8b"                 # LLM model name
max_concurrency = 5                     # Maximum concurrent requests
capability = 4                          # Capability level (1-5)

[embedding_pool]
enabled = true
strategy = "round_robin"

[[embedding_pool.providers]]
name = "qwen3-embedding"
base_url = "http://localhost:11434/v1"
key = ""
model_name = "qwen3-embedding:8b"
max_concurrency = 10
capability = 4

[sqvect]
top_k = 5                       # Number of relevant chunks to retrieve
threshold = 0.5                 # Similarity threshold (0.0 to 1.0)
index_type = "flat"             # Vector index type: hnsw, ivf, or flat

[chunker]
chunk_size = 500                # Number of characters per chunk
overlap = 50                    # Overlap between chunks
method = "sentence"             # Chunking method: sentence, paragraph, or token

[ingest]
[ingest.metadata_extraction]
enable = false                  # Extract metadata during ingestion (requires LLM)

[mcp]
enabled = true                  # Enable Model Context Protocol (MCP) tools
log_level = "info"
default_timeout = "5m"
max_concurrent_requests = 10
health_check_interval = "60s"
# Note: System automatically looks for mcpServers.json in your RAGO home directory