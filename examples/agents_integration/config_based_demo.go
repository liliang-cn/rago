package main

import (
	"context"
	"fmt"
	"os"

	"github.com/liliang-cn/rago/v2/pkg/agents/execution"
	"github.com/liliang-cn/rago/v2/pkg/agents/types"
	"github.com/liliang-cn/rago/v2/pkg/config"
	"github.com/liliang-cn/rago/v2/pkg/providers"
)

func main() {
	fmt.Println("üöÄ RAGO Workflow - Config-Based Provider Demo")
	fmt.Println("==============================================")
	fmt.Println()

	// Load configuration from rago.toml
	cfg, err := config.Load("")
	if err != nil {
		fmt.Printf("‚ùå Error loading config: %v\n", err)
		fmt.Println("üìù Please ensure rago.toml exists with proper provider configuration")
		os.Exit(1)
	}

	// Display which providers are being used
	fmt.Printf("üìã Configuration loaded:\n")
	fmt.Printf("   - Default LLM Provider: %s\n", cfg.Providers.DefaultLLM)
	fmt.Printf("   - Default Embedder Provider: %s\n", cfg.Providers.DefaultEmbedder)

	// Check which provider is configured
	if cfg.Providers.ProviderConfigs.LMStudio != nil {
		fmt.Printf("   - LMStudio URL: %s\n", cfg.Providers.ProviderConfigs.LMStudio.BaseURL)
		fmt.Printf("   - LMStudio Model: %s\n", cfg.Providers.ProviderConfigs.LMStudio.LLMModel)
	}
	if cfg.Providers.ProviderConfigs.Ollama != nil {
		fmt.Printf("   - Ollama URL: %s\n", cfg.Providers.ProviderConfigs.Ollama.BaseURL)
		fmt.Printf("   - Ollama Model: %s\n", cfg.Providers.ProviderConfigs.Ollama.LLMModel)
	}
	if cfg.Providers.ProviderConfigs.OpenAI != nil {
		fmt.Printf("   - OpenAI Model: %s\n", cfg.Providers.ProviderConfigs.OpenAI.LLMModel)
	}

	fmt.Println()

	// Initialize providers using the config (works with ANY configured provider)
	ctx := context.Background()
	_, llmService, _, err := utils.InitializeProviders(ctx, cfg)
	if err != nil {
		fmt.Printf("‚ùå Error initializing providers: %v\n", err)
		fmt.Println("üìù Please check your provider configuration in rago.toml")
		os.Exit(1)
	}

	fmt.Println("‚úÖ Providers initialized successfully!")
	fmt.Println()

	// Create a simple workflow
	workflow := &types.WorkflowSpec{
		Steps: []types.WorkflowStep{
			{
				ID:   "step1",
				Name: "Get Current Time",
				Type: types.StepType("tool"),
				Tool: "time",
				Inputs: map[string]interface{}{
					"action": "now",
					"format": "2006-01-02 15:04:05",
				},
				Outputs: map[string]string{
					"time": "current_time",
				},
			},
			{
				ID:   "step2",
				Name: "Analyze Time with LLM",
				Type: types.StepType("tool"),
				Tool: "sequential-thinking",
				Inputs: map[string]interface{}{
					"prompt": "The current time is {{current_time}}. Is this morning, afternoon, evening, or night? Respond in one sentence.",
				},
				Outputs: map[string]string{
					"analysis": "time_analysis",
				},
			},
			{
				ID:   "step3",
				Name: "Save Results",
				Type: types.StepType("tool"),
				Tool: "filesystem",
				Inputs: map[string]interface{}{
					"action":  "write",
					"path":    "/tmp/time_analysis.txt",
					"content": "Time Analysis Report\n====================\n\nTime: {{current_time}}\nAnalysis: {{time_analysis}}\n\nGenerated by RAGO using {{provider}} provider",
				},
				Outputs: map[string]string{
					"file": "output_file",
				},
			},
		},
		Variables: map[string]interface{}{
			"provider": cfg.Providers.DefaultLLM,
		},
	}

	// Execute the workflow
	fmt.Println("‚ö° Executing workflow...")
	executor := execution.NewWorkflowExecutorV2(cfg, llmService)
	executor.SetVerbose(true)

	result, err := executor.Execute(ctx, workflow)
	if err != nil {
		fmt.Printf("‚ùå Workflow execution failed: %v\n", err)
		os.Exit(1)
	}

	// Display results
	fmt.Println()
	fmt.Println("‚úÖ Workflow completed successfully!")
	fmt.Printf("‚è±Ô∏è  Execution time: %v\n", result.Duration)
	fmt.Println()

	fmt.Println("üìä Results:")
	if timeAnalysis, ok := result.Outputs["time_analysis"]; ok {
		fmt.Printf("   üïê Time: %v\n", result.Outputs["current_time"])
		fmt.Printf("   üìù Analysis: %v\n", timeAnalysis)
	}
	if outputFile, ok := result.Outputs["output_file"]; ok {
		fmt.Printf("   üìÅ Report saved to: %v\n", outputFile)
	}

	fmt.Println()
	fmt.Println("üéâ Demo complete! This workflow used the provider configured in rago.toml")
	fmt.Printf("   You can switch between Ollama, LMStudio, or OpenAI by updating the config.\n")
}
